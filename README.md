# RSTCANet
Residual Swin Transformer Channel Attention Network for Image Demosaicing

[Wenzhu Xing](https://scholar.google.com/citations?user=KvzPRbMAAAAJ&hl=en&oi=ao), [Karen Egiazarian](https://scholar.google.com/citations?user=PzvGG50AAAAJ&hl=en)

<hr />

> **Abstract:** *Image demosaicing is problem of interpolating full-resolution color images from raw sensor (color filter array) data. During last decade, deep neural networks have been widely used in image restoration, and in particular, in demosaicing, attaining significant performance improvement. In recent years, vision transformers have been designed and successfully used in various 
computer vision applications. One of the recent methods of image restoration based on a Swin Transformer (ST), SwinIR, demonstrates state-of-the-art performance with a smaller number of parameters than neural network-based methods. Inspired by the success of SwinIR, we propose in this paper a novel Swin Transformer-based network for image demosaicing, called RSTCANet. To extract image features, RSTCANet stacks several residual Swin Transformer Channel Attention blocks (RSTCAB), introducing the channel attention for each two successive ST blocks.
Extensive experiments demonstrate that RSTCANet outperforms state-of-the-art image demosaicing methods, and has a smaller number of parameters.*
<hr />

## Network Architecture

<img src = ""> 
